education:
  - school: Yale University
    location: New Haven, CT
    degree: Ph.D. in Computer Science
    dates: Expected May 2029
    details:
      - "Advisor: Alex Wong"
      - "Awards: NSF Graduate Research Fellowship (2025)"
  - school: Carnegie Mellon University
    location: Pittsburgh, PA
    degree: B.S. in Computer Science, Minor in Neural Computation, University Honors
    dates: May 2023

experience:
  industry:
    - company: RTX
      location: Remote
      role: Computer Vision Intern
      dates: June 2024 -- Present
      highlights:
        - "Proposed **ODE-GS**, a novel framework integrating 3D Gaussian Splatting with Transformer-based latent neural ODEs to enable continuous-time extrapolation of dynamic 3D scenes beyond the observed time window."
        - "Formulated dynamic scene extrapolation as a sequence-to-sequence problem by decoupling reconstruction from forecasting; utilized a Transformer encoder to aggregate past Gaussian trajectories into a latent state evolved via a neural ODE, eliminating timestamp dependency."
        - "Implemented a dynamic trajectory sampling strategy and an adaptive regularization mechanism (penalizing high-frequency oscillations in latent and 3D space) to enforce physical plausibility and spatio-temporal smoothness."
        - "Achieved State-of-the-Art (SOTA) performance on D-NeRF, NVFi, and HyperNeRF benchmarks, improving extrapolation metrics by an average of 21.4% PSNR compared to leading baselines like Deformable-GS and GaussianPrediction."
    - company: Futurewei Technologies (IC Lab)
      location: Remote
      role: Computer Vision Intern
      dates: May 2024 -- Aug 2024
      highlights:
        - "Proposed a novel pipeline for unseen 3D reconstruction and denoising, unifying 3D Gaussian Splatting (3DGS) with generative priors to resolve artifacts in occluded regions."
        - "Developed a 'Gaussian Importance' metric based on spatial variability to automatically detect and prune erroneous geometry (floaters/artifacts) without ground truth supervision."
        - "Extended the RePaint diffusion algorithm to 3D voxel representations, utilizing Optimal Transport matching to inpaint consistent geometry in pruned areas."
        - "Constructed a specialized multi-view dataset from Objaverse to benchmark limited-view reconstruction; outperformed SOTA methods (SplatFormer) by **+2.30 dB PSNR** and improved LPIPS scores."
    - company: Lenovo
      location: Remote
      role: Computer Vision Intern
      dates: June 2023 -- Aug 2023
      highlights:
        - "Developed and trained object detection and visual grounding models, improving model performance with limited memory resources."
        - "Pretrained the YOLOv8 backbone using masked image modeling (MIM) and fine-tuned the detector with elaborate augmentations."
        - "Secured 4th position in the 2023 VIPriors Object Detection Challenge in ICCV 2023 workshop."
  academic:
    - lab: Yale Vision Lab
      group: Yale University
      role: Research Assistant (Advisor: Alex Wong)
      dates: Aug 2023 -- Present
      projects:
        - name: Depth-prediction as Pretraining for Object Detection
          details:
            - "Evaluated a novel approach leveraging depth prediction as pretraining for object detection, demonstrating the effectiveness of depth-pretrained models over alternatives methods like dinoV2."
            - "Adapted a depth-pretrained ViT-L model as backbone on various detection and instance segmentation masks such as Mask-RCNN, Faster-RCNN."
            - "Conducted extensive experiments on various datasets and hyperparameter settings, achieving SOTA performance on COCO dataset and surpassing dinov2 backbone on cityscapes."
        - name: Unsupervised 3D Semantic Segmentation with Motion Prior
          details:
            - "Developed a novel approach for unsupervised 3D point cloud segmentation by leveraging motion cues."
            - "Employed soft contrastive learning to capture semantic similarities between 3D points."
            - "Developed a novel technique that trains encoder on multiple frame input but using single frame input during inference by leveraging 2d motion and projection from 3d to 2d points."
        - name: "UniTouch: Binding Touch to Everything"
          details:
            - "Contributed to the development of UniTouch, a unified tactile model connecting vision-based touch sensors to multiple modalities, including vision, language, and sound."
            - "Designed and implemented an automated labeling system on Amazon Mechanical Turk for efficient image crowdsourcing, facilitating large-scale data collection."
            - "Demonstrated UniTouch's zero-shot capabilities across various touch sensing tasks, from robot grasping prediction to touch image question answering, setting a new benchmark in multimodal tactile sensing."
        - name: Variational Language Prior for Monocular Depth Estimation
          details:
            - "Introduced WorDepth, a novel method that leverages a variational approach to integrate language as a prior in Monocular Depth Estimation."
            - "Utilized CLIP, a visual-language model, to exploit the semantic priors learned from its large-scale training data and guide the depth model with geometry priors associated with semantics."
            - "Developed a three-stage approach: 1) Variational modeling of language prior, 2) Conditioned sampling from the scene layout distribution, and 3) Language prior-assisted depth estimator training."
            - "Demonstrated state-of-the-art performance on the NYU Depth V2 and KITTI depth datasets, confirming the effectiveness of integrating language priors in depth estimation."
    - lab: Lee's Lab
      group: Carnegie Mellon University
      role: Research Assistant (Advisor: Tai-Sing Lee)
      dates: Aug 2021 -- May 2023
      projects:
        - name: Revealing the Complexity of V1 Neural Codes via CNN Modeling
          details:
            - "Analyzed 2-photon calcium imaging data set of 1000 neurons' responses to 35K-50K natural images."
            - "Implemented and tuned the Shared Core Convolution Neural Network (CNN) model and predicted the collective response of all neurons in each site simultaneously."
            - "Achieved state-of-the-art prediction performance in response correlation and tuning curve fitting."
            - "Visualized neurons with image gradient descent algorithm based on negative max response loss function."
            - "Demonstrated that trained neural networks reveal complex behaviors of V1 neurons, and the percentage of discovered complex neurons has a positive correlation with training set size."
        - name: Investigating Contextual Processing in V1 Using Neurons In-Silico
          details:
            - "Observed with model experiments that image encoder only has high responses to the center area of the input, aligning with V1 neuron's receptive fields, while also showing surround suppression."
            - "Experimented with various machine learning methods for reconstruction, such as direct CNN decoding, VAE latent space mapping, conditional GAN."
            - "Reconstructed full-image details using generated response from image encoder and data-driven decoder."
            - "Revealed that the CNN image encoder displays V1 neurons' contextual modulation effect and suggests that trained neural networks can serve as V1 neurons in-silico for investigating neural mechanisms."

skills:
  programming: C, C++, Python, Java, SQL, SML, HTML, CSS, JavaScript, GO
  data_analysis: PyTorch, MATLAB, R
  software_tools: Microsoft Office, Git, LaTeX, Linux

service:
  reviewer:
    - CVPR (2025, 2026)
    - ICLR (2025, 2026)
    - NeurIPS (2024, 2025)
