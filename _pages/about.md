---
permalink: /
title: ""
excerpt: "Ph.D. Student at Yale University"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I am a 3rd year Ph.D. student in Computer Science at **Yale University**, advised by [Alex Wong](https://alexwong.net). My research interests lie in **Computer Vision** and **Neural Machine Translation**. Previously, I received my B.S. in Computer Science from **Carnegie Mellon University** with University Honors and a Minor in Neural Computation.

You can find my full CV [here](files/cv.pdf) (placeholder link).

<a href='https://scholar.google.com/citations?user=Rk_pDPEAAAAJ&hl=en'><img src="https://img.shields.io/endpoint?url={{ url | url_encode }}&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations"></a>

# ğŸ”¥ News
- *2024.06*: &nbsp;ğŸ‰ğŸ‰ Joined **RTX** as a Computer Vision Intern.
- *2024.05*: &nbsp;ğŸ‰ğŸ‰ Joined **Futurewei Technologies** as a Computer Vision Intern.
- *2023.08*: &nbsp;ğŸ‰ğŸ‰ Started Ph.D. in Computer Science at **Yale University**.
- *2023.06*: &nbsp;ğŸ‰ğŸ‰ Joined **Lenovo** as a Computer Vision Intern.

# ğŸ“ Selected Publications 

<div class='paper-box'><div class='paper-box-text' markdown="1">

[ODE-GS: Latent ODEs for Dynamic Scene Extrapolation with 3D Gaussian Splatting](javascript:void(0))

**D. Wang**, P. Rim, T. Tian, A. Wong, G. Sundaramoorthi

*arXiv Preprint*, 2024. (Under review at ICLR 2026)
</div></div>

<div class='paper-box'><div class='paper-box-text' markdown="1">

[Binding touch to everything: Learning unified multimodal tactile representations](javascript:void(0))

F. Yang, C. Feng, Z. Chen, H. Park, **D. Wang**, Y. Dou, et al.

*Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)*, 2024.
</div></div>

<div class='paper-box'><div class='paper-box-text' markdown="1">

[WorDepth: Variational language prior for monocular depth estimation](javascript:void(0))

Z. Zeng, **D. Wang**, F. Yang, H. Park, S. Soatto, D. Lao, A. Wong

*Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)*, 2024.
</div></div>

<div class='paper-box'><div class='paper-box-text' markdown="1">

[On the viability of monocular depth pre-training for semantic segmentation](javascript:void(0))

D. Lao, F. Yang, **D. Wang**, H. Park, S. Lu, A. Wong, S. Soatto

*European Conference on Computer Vision (ECCV)*, 2024.
</div></div>

# ğŸ– Honors and Awards
- *2025* **NSF Graduate Research Fellowship** ğŸ†
- *2023* 4th position in the 2023 VIPriors Object Detection Challenge (ICCV 2023 workshop)
- *2023* University Honors, Carnegie Mellon University (2023)

# ğŸ“– Education
- *2023.08 - Present*, **Yale University**, New Haven, CT
  - Ph.D. in Computer Science (Expected May 2029)
  - Advisor: Alex Wong
  - Awards: **NSF Graduate Research Fellowship (2025)**

- *2019.08 - 2023.05*, **Carnegie Mellon University**, Pittsburgh, PA
  - B.S. in Computer Science, Minor in Neural Computation
  - University Honors

# ğŸ’» Industry Experience
- *2024.06 - Present*, **RTX**, Remote
  - Computer Vision Intern
  - Proposed **ODE-GS**, a novel framework integrating 3D Gaussian Splatting with Transformer-based latent neural ODEs.
  - Achieved SOTA performance on D-NeRF, NVFi, and HyperNeRF benchmarks.

- *2024.05 - 2024.08*, **Futurewei Technologies (IC Lab)**, Remote
  - Computer Vision Intern
  - Proposed a novel pipeline for unseen 3D reconstruction and denoising.
  - Developed a "Gaussian Importance" metric to prune erroneous geometry.
  - Outperformed SOTA methods (SplatFormer) by **+2.30 dB PSNR**.

- *2023.06 - 2023.08*, **Lenovo**, Remote
  - Computer Vision Intern
  - Developed and trained object detection and visual grounding models.
  - Pretrained YOLOv8 backbone using masked image modeling (MIM).
  - Secured 4th position in the 2023 VIPriors Object Detection Challenge.

# ğŸ›  Technical Skills
- **Programming:** C, C++, Python, Java, SQL, SML, HTML, CSS, JavaScript, GO
- **Data Analysis:** PyTorch, MATLAB, R
- **Software & Tools:** Microsoft Office, Git, LaTeX, Linux

# ğŸ Academic Service
- **Reviewer:** CVPR (2025, 2026), ICLR (2025, 2026), NeurIPS (2024, 2025)