---
permalink: /
title: ""
excerpt: "Ph.D. Student at Yale University"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I am a 3rd year Ph.D. student in Computer Science at **Yale University**, advised by [Alex Wong](https://alexwong.net). My research interests lie in **3D Computer Vision**, **Multi-modal Machine Learning**, and **Representation Learning**. Previously, I received my B.S. in Computer Science from **Carnegie Mellon University** with University Honors and a Minor in Neural Computation, advised by [Tai-Sing Lee](https://www.cnbc.cmu.edu/~tai/). I had collaborated with the excellent research teams at **RTX**, **Futurewei Technologies**, and **Lenovo** for my past internships.

You can find my full CV [here](files/cv.pdf) (placeholder link).

<a href='https://scholar.google.com/citations?user=Rk_pDPEAAAAJ&hl=en'><img src="https://img.shields.io/endpoint?url={{ url | url_encode }}&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations"></a>

<div style="padding: 1.5rem; background: linear-gradient(135deg, #f0f7ff 0%, #faf9f7 100%); border-radius: 12px; border-left: 4px solid #3b7dd8; margin-top: 2rem; margin-bottom: 2rem;">
    <div style="font-family: 'Inter', sans-serif; font-size: 0.95rem; color: #374151; font-weight: 500; margin-bottom: 0.5rem;">
        NSF Graduate Research Fellowship (2025) ğŸ†
    </div>
    <div style="font-size: 0.9rem; color: #6b7280;">
        Honored to receive support for my research in 3D Computer Vision.
    </div>
</div>


<span class='anchor' id='news'></span>
# ğŸ”¥ News
- *2024.06*: &nbsp;ğŸ‰ğŸ‰ Joined **RTX** as a Computer Vision Intern.
- *2024.05*: &nbsp;ğŸ‰ğŸ‰ Joined **Futurewei Technologies** as a Computer Vision Intern.
- *2023.08*: &nbsp;ğŸ‰ğŸ‰ Started Ph.D. in Computer Science at **Yale University**.
- *2023.06*: &nbsp;ğŸ‰ğŸ‰ Joined **Lenovo** as a Computer Vision Intern.

<span class='anchor' id='publications'></span>
# ğŸ“ Selected Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Under review: ICLR 2026</div><img src='images/odegs.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[ODE-GS: Latent ODEs for Dynamic Scene Extrapolation with 3D Gaussian Splatting](https://arxiv.org/abs/2506.05480)

**D. Wang**, P. Rim, T. Tian, A. Wong, G. Sundaramoorthi

*Under review at ICLR 2026*

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2024</div><img src='images/UniTouch.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Binding touch to everything: Learning unified multimodal tactile representations](https://openaccess.thecvf.com/content/CVPR2024/html/Yang_Binding_Touch_to_Everything_Learning_Unified_Multimodal_Tactile_Representations_CVPR_2024_paper.html)

F. Yang, C. Feng, Z. Chen, H. Park, **D. Wang**, Y. Dou, et al.

*Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)*, 2024.

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2024</div><img src='images/WorDepth.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[WorDepth: Variational language prior for monocular depth estimation](https://arxiv.org/abs/2404.03635)

Z. Zeng, **D. Wang**, F. Yang, H. Park, S. Soatto, D. Lao, A. Wong

*Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)*, 2024.

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ECCV 2024</div><img src='images/depthpre.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[On the viability of monocular depth pre-training for semantic segmentation](https://arxiv.org/abs/2203.13987)

D. Lao, F. Yang, **D. Wang**, H. Park, S. Lu, A. Wong, S. Soatto

*European Conference on Computer Vision (ECCV)*, 2024.

</div>
</div>

<span class='anchor' id='skills'></span>
# ğŸ›  Technical Skills
- **Programming:** C, C++, Python, Java, SQL, SML, HTML, CSS, JavaScript, GO


<span class='anchor' id='honors'></span>
# ğŸ– Honors and Awards
- *2025* **NSF Graduate Research Fellowship** ğŸ†
- *2023* 4th position in the 2023 VIPriors Object Detection Challenge (ICCV 2023 workshop)
- *2023* University Honors, Carnegie Mellon University (2023)

<span class='anchor' id='education'></span>
# ğŸ“– Education
- *2023.08 - Present*, **Yale University**, New Haven, CT

- *2019.08 - 2023.05*, **Carnegie Mellon University**, Pittsburgh, PA

<span class='anchor' id='experience'></span>
# ğŸ’» Industry Experience
- *2025.05 - 2025.08*, **Futurewei Technologies (IC Lab)**, Santa Clara, CA

- *2024.06 - 2024-12*, **RTX**, Hartford, CT

- *2023.06 - 2023.08*, **Lenovo**, Beijing, China

<span class='anchor' id='service'></span>
# ğŸ Academic Service
- **Reviewer:** CVPR (2025, 2026), ICLR (2025, 2026), NeurIPS (2024, 2025)

<script type="text/javascript" id="mapmyvisitors" src="//mapmyvisitors.com/map.js?d=GO4IA0rrJ5OaTEqd2tJfw5POEs-FHBxW091CxOql7OI&cl=ffffff&w=a"></script>

