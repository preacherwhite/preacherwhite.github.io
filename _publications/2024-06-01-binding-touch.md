---
title: "Binding touch to everything: Learning unified multimodal tactile representations"
collection: publications
permalink: /publication/2024-06-01-binding-touch
excerpt: "Developing unified multimodal tactile representations connecting vision-based touch sensors to vision, language, and sound."
date: 2024-06-01
venue: 'CVPR 2024'
paperurl: ''
image: '/images/unitouch.png'
authors: 'F. Yang, C. Feng, Z. Chen, H. Park, <strong>D. Wang</strong>, Y. Dou, et al.'
---
Binding touch to everything: Learning unified multimodal tactile representations.
- Contributed to the development of UniTouch, a unified tactile model.
- Demonstrated zero-shot capabilities across various touch sensing tasks.
